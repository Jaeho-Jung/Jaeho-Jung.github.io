---
title: "Crawler의 Issue"
description: "Crawling의 Issue에 대해 설명한다."
date: "2023-10-3"
categories:
    - Information Retrieval
    - Crawler
---

## Issue

### Performance & Efficiency

---

#### Distribution


### Scalability

---

### Search Strategy

---

1. Where to Start

2. Link ordering

- DFS (LIFO)
- BFS (FIFO)
- Best-first Algorithm
- Fish

3. Circularities

4. Duplicates

5. Checking for changes

### Robustness

---

- Be immune to `spider traps` and other malcious behavior from web servers

### Politeness

---

#### Explicit Politeness

---

##### `Robots.txt`

<http://www.robotstxt.org/>\
*The Robots Exclusion Protocol.*\

- `정의`: 사이트나 문서에 대한 로봇들의 접근을 제어하기 위한 표준 규약이다.
    - 웹사이트의 어떤 부분을 크롤링해도 되는지에 대한 명세로, 웹사이트 관리자가 작성한다.
- `작동 방식`: 로봇이 웹사이트의 URL에 접근하기 전에, 해당 웹사이트의 robots.txt 파일을 확인하여 규약에 따른다.
- `위치`: 웹 서버 최상위 경로에 위치한다. 
    - e.g. <https://www.google.com/robots.txt>

**Example**
```text
User-agent: *
Disallow: /yoursite/temp/

User-agent: searchengine
Disallow: 
```

#### Implicit Politeness

- don't hit a server too often


- Respect implicit and explicit politeness considerations

### Parsing Pages for Links

---

### Malcious servers: SEOs

---

#### Spam Pages

#### Spider traps

- incl dynamically generated
- infinite URL names
- Ill-formed HTML
    - E.g. page with 68kB of null characters
- Misleading sites
    - indefinite number of pages dynamically generated by CGI scripts
    - paths of arbitrary depth created using soft directory links and path remapping features in HTTP server

**Solution**

- Check for URL length
- Guards
    - regular crawl statistics
    - Adding dominating sites to guard module
    - CGI form quaries와 같은 내용의 크롤링 비활성화
    - 텍스트 데이터 타입이 아닌 URL 제거

### Freshness

---

Continue fetching fresh copies of a previously fetched page

### Extensibility

---

Adapt to new data formats, protocols

### Storage

---

- 일반적인 HTML 웹 페이지는 압축 시 2-4 kB
    - [zlib](https://www.zlib.net/)
        - Deflate 압축 알고리즘을 C언어로 구현한 라이브러리
        - 비손실 압축 알고리즘
        - 높은 이식성
        - 압축 알고리즘계의 산업 표준

- 작은 규모의 시스템
    - `Storage Manager` 사용 (E.g. Berkeley DB)
    - 디스크 기반의 데이터베이스 관리
    - configuration as a hash-table/B-tree for URL access key
    - configuration as a sequential log of page records.

- 큰 규모의 시스템

## References