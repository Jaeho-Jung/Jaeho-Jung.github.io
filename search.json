[
  {
    "objectID": "posts/Markdown/markdown_basics.html",
    "href": "posts/Markdown/markdown_basics.html",
    "title": "Markdown 기초 문법",
    "section": "",
    "text": "마크다운(Markdown)은 마크업 언어(Markup Language)의 일종으로, 2004년에 존 그루버(John Gruber)가 만들었다. 일반 텍스트로 서식이 있는 문서를 작성하는 데에 사용되며, 문법이 간단하여 읽고 쓰기 쉽다.\n\n\n\n\n\n\nNote\n\n\n\n파일 확장자는 .md, .markdown이다.\n\n\n\n\n\n\nVersatile: 마크다운은 웹사이트, 문서, 노트, 책, 프레젠테이션, 이메일 메시지 및 기술 문서 작성 등 다양한 용도로 사용할 수 있다.\nPortable: 마크다운 형식의 텍스트 파일은 거의 모든 응용 프로그램에서 열 수 있다.\nPlatform independent: 모든 운영 체제에서 마크다운 형식 텍스트를 생성할 수 있다.\nFuture-Proof: 애플리케이션이 작동을 멈춘다 하더라도 텍스트 편집 애플리케이션을 사용하여 마크다운 형식의 텍스트를 계속 읽을 수 있다.\nSupport: Reddit, GitHub 등 많은 데스크탑과 웹 기반 애플리케이션에서 마크다운을 지원한다."
  },
  {
    "objectID": "posts/Markdown/markdown_basics.html#개요",
    "href": "posts/Markdown/markdown_basics.html#개요",
    "title": "Markdown 기초 문법",
    "section": "",
    "text": "마크다운(Markdown)은 마크업 언어(Markup Language)의 일종으로, 2004년에 존 그루버(John Gruber)가 만들었다. 일반 텍스트로 서식이 있는 문서를 작성하는 데에 사용되며, 문법이 간단하여 읽고 쓰기 쉽다.\n\n\n\n\n\n\nNote\n\n\n\n파일 확장자는 .md, .markdown이다.\n\n\n\n\n\n\nVersatile: 마크다운은 웹사이트, 문서, 노트, 책, 프레젠테이션, 이메일 메시지 및 기술 문서 작성 등 다양한 용도로 사용할 수 있다.\nPortable: 마크다운 형식의 텍스트 파일은 거의 모든 응용 프로그램에서 열 수 있다.\nPlatform independent: 모든 운영 체제에서 마크다운 형식 텍스트를 생성할 수 있다.\nFuture-Proof: 애플리케이션이 작동을 멈춘다 하더라도 텍스트 편집 애플리케이션을 사용하여 마크다운 형식의 텍스트를 계속 읽을 수 있다.\nSupport: Reddit, GitHub 등 많은 데스크탑과 웹 기반 애플리케이션에서 마크다운을 지원한다."
  },
  {
    "objectID": "posts/Markdown/markdown_basics.html#문법",
    "href": "posts/Markdown/markdown_basics.html#문법",
    "title": "Markdown 기초 문법",
    "section": "문법",
    "text": "문법\n\n제목(Headings)\n\n\n\n\n\n\n\nMarkdown 문법\n출력\n\n\n\n\n# 제목 1\n제목 1\n\n\n## 제목 2\n제목 2\n\n\n### 제목 3\n제목 3\n\n\n#### 제목 4\n제목 4\n\n\n##### 제목 5\n제목 5\n\n\n###### 제목 6\n제목 6\n\n\n\n\n\n텍스트 포맷(Text Formatting)\n\n\n\n\n\n\n\nMarkdown 문법\n출력\n\n\n\n\n*이탤릭체*, **굵게**, ***굵은 이탤릭체***\nitalics, bold, bold italics\n\n\n위 첨자^2^ / 아래 첨자~2~\nsuperscript2 / subscript2\n\n\n~~취소선~~\nstrikethrough\n\n\n`코드 강조`\nverbatim code\n\n\n\n\n\n목록(Lists)\n\n1. 순서 있는 목록\n목록 숫자는 1로 시작해야 하며, 오름차순이 아니어도 된다.\n\n\n\n\n\n\n\nMarkdown 문법\n출력\n\n\n\n\n1. First item\n2. Second item\n3. Third item\n\nFirst item\nSecond item\nThird item\n\n\n\n1. First item\n1. Second item\n1. Third item\n\nFirst item\nSecond item\nThird item\n\n\n\n1. First item\n8. Second item\n5. Third item\n\nFirst item\nSecond item\nThird item\n\n\n\n1. First item\n2. Second item\n    1. Indented item\n    2. Indented item\n3. Third item\n\nFirst item\nSecond item\n\nIndent item\nIndent item\n\nThird item\n\n\n\n\n\n\n\n2. 순서 없는 목록\n-,*,+을 사용하여 순서 없는 목록을 생성할 수 있다.\n\n\n\n\n\n\n\nMarkdown 문법\n출력\n\n\n\n\n- First item\n- Second item\n- Third item\n\nFirst item\nSecond item\nThird item\n\n\n\n* First item\n* Second item\n* Third item\n\nFirst item\nSecond item\nThird item\n\n\n\n+ First item\n+ Second item\n+ Third item\n\nFirst item\nSecond item\nThird item\n\n\n\n- First item\n- Second item\n    - Indented item\n    - Indented item\n- Third item\n\nFirst item\nSecond item\n\nIndent item\nIndent item\n\nThird item\n\n\n\n\n\n\n\n3. 목록에 요소(Element) 추가\n목록에 다른 요소를 추가하려면 요소 앞에 들여쓰기 4칸을 삽입한다.\n* First item\n* Second item\n    - Indented item\n\n        &gt; Blockquote\n    \n    - Indented item\n* Third item\n\nFirst item\nSecond item\n\nIndented item\n\nBlockquote\n\nIndented item\n\nThird item\n\n\n\n\n\n블록(Blocks)\n\n1. 코드 블록(Code Blocks)\n\nFenced Code Blocks\n코드 위와 아래를 ``` 또는 ~~~로 감싸 코드 블럭을 만들 수 있다.\n```\na = 5\nif a % 2 == 0:\n  print(\"even\")\nelse:\n  print(\"odd\")\n```\na = 5\nif a % 2 == 0:\n  print(\"even\")\nelse:\n  print(\"odd\")\n\n\n구문 강조(Syntax Highlighting)\n구문 강조를 위해서 첫 ``` 뒤에 코드 작성에 사용된 언어를 적는다.\n```python\na = 5\nif a % 2 == 0:\n  print(\"even\")\nelse:\n  print(\"odd\")\n```\na = 5\nif a % 2 == 0:\n  print(\"even\")\nelse:\n  print(\"odd\")\n\n\n\n\n2. 인용문 블록(Blockquotes)\n&gt; Blockquotes\n\nBlockquotes\n\n&gt; Blockquotes\n&gt;\n&gt; with Multiple Paragraphs\n\nBlockquotes\nwith Multiple Paragraphs\n\n&gt; Blockquotes\n&gt;\n&gt;&gt; Nested Blockquotes\n\nBlockquotes\n\nNested Blockquotes\n\n\n&gt; #### Headings\n&gt;\n&gt; - Unordered Lists\n&gt; - Unordered Lists\n&gt;\n&gt; *italics* **bold**\n\nHeadings\n\nUnordered Lists\nUnordered Lists\n\nitalics bold\n\n\n\n\n\n\n링크 & 이미지(Links & Images)\n\n\n\nMarkdown 문법\n출력\n\n\n\n\n&lt;https://jaeho-jung.github.io/&gt;\nhttps://jaeho-jung.github.io/\n\n\n[Jaeho-Jung's Blog](https://jaeho-jung.github.io/)\nJaeho-Jung’s Blog\n\n\n![Caption](markdown.svg)\n\n\n\n[![Caption](markdown.svg)](https://jaeho-jung.github.io/)\n\n\n\n[![Caption](markdown.svg)](https://jaeho-jung.github.io/)\n\n\n\n[![](markdown.svg){fig-alt=\"Alt text\"}](https://jaeho-jung.github.io/)"
  },
  {
    "objectID": "posts/Markdown/markdown_basics.html#references",
    "href": "posts/Markdown/markdown_basics.html#references",
    "title": "Markdown 기초 문법",
    "section": "References",
    "text": "References\nhttps://www.markdownguide.org/getting-started/\nhttps://www.markdownguide.org/basic-syntax/\nhttps://www.markdownguide.org/extended-syntax/#fenced-code-blocks\nhttps://quarto.org/docs/authoring/markdown-basics.html\nhttps://ko.wikipedia.org/wiki/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4"
  },
  {
    "objectID": "posts/Crawler/crawler.html",
    "href": "posts/Crawler/crawler.html",
    "title": "Crawler란?",
    "section": "",
    "text": "자동으로 웹페이지를 찾고 다운로드하는 프로그램\n\n\n\n\n웹 크롤러 봇은, 정리되지 않은 도서관의 모든 책을 검토하고 카드 카탈로그를 구성함으로써, 도서관을 찾는 이가 필요한 정보를 빠르고 쉽게 찾을 수 있도록 도와주는 사람과 유사합니다. 이 사람은 도서관의 책을 주제별로 분류하고 정렬할 수 있도록, 책의 제목, 요약, 본문 중 일부를 읽어 무엇에 대한 책인지 파악할 것입니다.\n\n\n\n웹 크롤러란? | 웹 스파이더의 작동 원리, Cloudflare\n\n\n\nWorld Wide Web 거미가 거미줄을 기어다니듯이 검색 엔진 봇이 “Web” 전체를 기어다닌다."
  },
  {
    "objectID": "posts/Crawler/crawler.html#정의",
    "href": "posts/Crawler/crawler.html#정의",
    "title": "Crawler란?",
    "section": "",
    "text": "자동으로 웹페이지를 찾고 다운로드하는 프로그램\n\n\n\n\n웹 크롤러 봇은, 정리되지 않은 도서관의 모든 책을 검토하고 카드 카탈로그를 구성함으로써, 도서관을 찾는 이가 필요한 정보를 빠르고 쉽게 찾을 수 있도록 도와주는 사람과 유사합니다. 이 사람은 도서관의 책을 주제별로 분류하고 정렬할 수 있도록, 책의 제목, 요약, 본문 중 일부를 읽어 무엇에 대한 책인지 파악할 것입니다.\n\n\n\n웹 크롤러란? | 웹 스파이더의 작동 원리, Cloudflare\n\n\n\nWorld Wide Web 거미가 거미줄을 기어다니듯이 검색 엔진 봇이 “Web” 전체를 기어다닌다."
  },
  {
    "objectID": "posts/Crawler/crawler.html#역할",
    "href": "posts/Crawler/crawler.html#역할",
    "title": "Crawler란?",
    "section": "역할",
    "text": "역할\n\ndownloading pages\nfinding URLs.\n\nseeds: set of URLs given to it as parameters"
  },
  {
    "objectID": "posts/Crawler/crawler.html#problems",
    "href": "posts/Crawler/crawler.html#problems",
    "title": "Crawler란?",
    "section": "Problems",
    "text": "Problems\n\n웹의 규모: 웹의 규모는 매우 크며 매 순간 생성되고 있기 때문에 얼마나 많은 웹페이지가 존재하는지 측정할 수 없다. 대부분의 조직들은 웹페이지를 저장할 수 있는 저장공간이 부족하지만 freshness를 유지하기 위해 끊임없이 새 문서들을 저장해야 한다.\n규약: 웹사이트의 주인이 크롤링을 원치 않을 수 있다."
  },
  {
    "objectID": "posts/Crawler/crawler.html#정책",
    "href": "posts/Crawler/crawler.html#정책",
    "title": "Crawler란?",
    "section": "정책",
    "text": "정책"
  },
  {
    "objectID": "posts/Crawler/crawler.html#규약",
    "href": "posts/Crawler/crawler.html#규약",
    "title": "Crawler란?",
    "section": "규약",
    "text": "규약\n\nrobots.txt\nhttp://www.robotstxt.org/\nThe Robots Exclusion Protocol.\n\n\n정의: 사이트나 문서에 대한 로봇들의 접근을 제어하기 위한 표준 규약이다.\n작동 방식: 로봇이 웹사이트의 URL에 접근하기 전에, 해당 웹사이트의 robots.txt 파일을 확인하여 규약에 따른다.\n위치: 웹사이트의 최상위 경로에 존재한다.\n\n\nurllib.robotparser\nhttps://docs.python.org/3/library/urllib.robotparser.html"
  },
  {
    "objectID": "posts/Crawler/crawler.html#평가-방법",
    "href": "posts/Crawler/crawler.html#평가-방법",
    "title": "Crawler란?",
    "section": "평가 방법",
    "text": "평가 방법\n\nFreshness\n\n\nCoverage"
  },
  {
    "objectID": "posts/Crawler/crawler.html#references",
    "href": "posts/Crawler/crawler.html#references",
    "title": "Crawler란?",
    "section": "References",
    "text": "References\n문서\nhttp://www.robotstxt.org/\nhttps://www.cloudflare.com/ko-kr/learning/bots/what-is-a-web-crawler/\nhttps://policy.naver.com/policy/search_policy.html\nhttps://en.wikipedia.org/wiki/Web_crawler\nhttps://ciir.cs.umass.edu/downloads/SEIRiP.pdf\nhttps://developers.google.com/search/docs/crawling-indexing/overview-google-crawlers?hl=ko\n\n오픈소스 크롤러 https://help.oncrawl.com/en/articles/2767544-oncrawl-crawler-what-counts-as-a-single-url\nhttps://github.com/scrapy/scrapy/blob/2.11/scrapy/robotstxt.py\n코드\nhttps://nwpct1.hatenablog.com/entry/python-search-engine\n\n논문\nhttps://www.sciencedirect.com/science/article/abs/pii/S1389128600000578\nhttps://proceedings.neurips.cc/paper/2013/hash/b3ba8f1bee1238a2f37603d90b58898d-Abstract.html\n\n책 https://ciir.cs.umass.edu/downloads/SEIRiP.pdf"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jaeho-Jung's blog",
    "section": "",
    "text": "Markdown 기초 문법\n\n\n\n\n\n\n\nmarkdown\n\n\nguide\n\n\nsyntax\n\n\n\n\nMarkdown 소개 및 기초 문법 정리\n\n\n\n\n\n\nSep 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\nCrawler란?\n\n\n\n\n\n\n\ninformation retrieval\n\n\ncrawler\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2023\n\n\nJaeho Jung\n\n\n\n\n\n\n  \n\n\n\n\n[Information Retrieval] Music Search Engine\n\n\n\n\n\n\n\ninformation retrieval\n\n\n\n\n음악 검색 엔진 Informaiton Retrieval 프로젝트\n\n\n\n\n\n\nJan 1, 2023\n\n\nJaeho Jung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Crawler/music_serach_engine.html",
    "href": "posts/Crawler/music_serach_engine.html",
    "title": "[Information Retrieval] Music Search Engine",
    "section": "",
    "text": "Music streaming services: Spotify, Apple Music, Amazon Music, YouTube Music, etc.\nMusic databases: Discogs, MusicBrainz, AllMusic, etc.\nMusic news websites: Pitchfork, Rolling Stone, Billboard, etc.\nMusic review websites: Metacritic, RateYourMusic, etc.\nMusic social media websites: Last.fm, Reddit, Twitter, etc.\nWebsites that focus on specific genreso f music\nMusic Blogs\nMusic Forums\nLyrics website\nArtist Website\nMusic Review Aggregators\n\n수집 데이터\n\nTitle: The title of the web page or article.\nContent: The main textual content of the web page.\nURL: The URL of the web page.\nAuthor: If available, the name of the author or contributor.\nPublication Date: The date when the web page was published or last updated.\nTags or Categories: Music genres, artists, albums, or other relevant categories.\nLinks: Links to other related pages within the website or to external sources.\nImages: Thumbnails or images associated with music albums or artists.\nMetadata: Any additional metadata provided on the web page, such as Song title, artist name, album name, release date, genre, etc.\nLyrics: The lyrics to the song. Audio: The audio file of the song.\nLinks to other music pages: This will help you to discover new music and build a more comprehensive index.\n어떤 아티스트들이 같이 언급되는지\n어떤 아티스트들이 같이 투어하는지\n어떤 아티스트에 대한 관심이 느는지\n어떤 아티스트에 대한 관심이 주는지\n최신 유행 곡 탐색\n\n\n\n\n\n규정 준수\n음악 웹사이트 데이터 수집 목적으로 설계된 크롤러 사용\n저작권\n\n\n\n\n\n\n\n크롤러는 웹 페이지상의 링크를 따라가며 웹사이트를 스캔한다.\n이를 구현하기 위해서는 웹 페이지에서 URL 링크를 찾아야한다.\nHTML링크는 &lt;a href=\"URL\"와 같은 형식으로 이루어져 있다.\npython의 find() 함수와 slice 기능을 사용하여 링크 추출 기능을 구현한다.\n\nprocedure CrawlerThread(frontier)\n    while not frontier.done() do\n        website := frontier.nextSite()\n        url := website.nextURL()\n        if website.permitsCrawl(url) then\n            text := retrieveURL(url)\n            storeDocument(url, text)\n            for each url in parse(text) do\n                frontier.addURL(url)\n            end for\n        end if\n        frontier.releaseSite(website)\n    end while\nend procedure\n\ncrawl frontier: data structure used for storage of URLs eligible for crawling and supporting such operations as adding URLs and selecting for crawl."
  },
  {
    "objectID": "posts/Crawler/music_serach_engine.html#정보-수집",
    "href": "posts/Crawler/music_serach_engine.html#정보-수집",
    "title": "[Information Retrieval] Music Search Engine",
    "section": "",
    "text": "Music streaming services: Spotify, Apple Music, Amazon Music, YouTube Music, etc.\nMusic databases: Discogs, MusicBrainz, AllMusic, etc.\nMusic news websites: Pitchfork, Rolling Stone, Billboard, etc.\nMusic review websites: Metacritic, RateYourMusic, etc.\nMusic social media websites: Last.fm, Reddit, Twitter, etc.\nWebsites that focus on specific genreso f music\nMusic Blogs\nMusic Forums\nLyrics website\nArtist Website\nMusic Review Aggregators\n\n수집 데이터\n\nTitle: The title of the web page or article.\nContent: The main textual content of the web page.\nURL: The URL of the web page.\nAuthor: If available, the name of the author or contributor.\nPublication Date: The date when the web page was published or last updated.\nTags or Categories: Music genres, artists, albums, or other relevant categories.\nLinks: Links to other related pages within the website or to external sources.\nImages: Thumbnails or images associated with music albums or artists.\nMetadata: Any additional metadata provided on the web page, such as Song title, artist name, album name, release date, genre, etc.\nLyrics: The lyrics to the song. Audio: The audio file of the song.\nLinks to other music pages: This will help you to discover new music and build a more comprehensive index.\n어떤 아티스트들이 같이 언급되는지\n어떤 아티스트들이 같이 투어하는지\n어떤 아티스트에 대한 관심이 느는지\n어떤 아티스트에 대한 관심이 주는지\n최신 유행 곡 탐색\n\n\n\n\n\n규정 준수\n음악 웹사이트 데이터 수집 목적으로 설계된 크롤러 사용\n저작권\n\n\n\n\n\n\n\n크롤러는 웹 페이지상의 링크를 따라가며 웹사이트를 스캔한다.\n이를 구현하기 위해서는 웹 페이지에서 URL 링크를 찾아야한다.\nHTML링크는 &lt;a href=\"URL\"와 같은 형식으로 이루어져 있다.\npython의 find() 함수와 slice 기능을 사용하여 링크 추출 기능을 구현한다.\n\nprocedure CrawlerThread(frontier)\n    while not frontier.done() do\n        website := frontier.nextSite()\n        url := website.nextURL()\n        if website.permitsCrawl(url) then\n            text := retrieveURL(url)\n            storeDocument(url, text)\n            for each url in parse(text) do\n                frontier.addURL(url)\n            end for\n        end if\n        frontier.releaseSite(website)\n    end while\nend procedure\n\ncrawl frontier: data structure used for storage of URLs eligible for crawling and supporting such operations as adding URLs and selecting for crawl."
  },
  {
    "objectID": "posts/Crawler/music_serach_engine.html#collaborative-filtering",
    "href": "posts/Crawler/music_serach_engine.html#collaborative-filtering",
    "title": "[Information Retrieval] Music Search Engine",
    "section": "Collaborative Filtering",
    "text": "Collaborative Filtering\n음악 추천에 쓰임"
  },
  {
    "objectID": "posts/Crawler/music_serach_engine.html#audio-analysis",
    "href": "posts/Crawler/music_serach_engine.html#audio-analysis",
    "title": "[Information Retrieval] Music Search Engine",
    "section": "Audio Analysis",
    "text": "Audio Analysis"
  },
  {
    "objectID": "posts/Crawler/music_serach_engine.html#references",
    "href": "posts/Crawler/music_serach_engine.html#references",
    "title": "[Information Retrieval] Music Search Engine",
    "section": "References",
    "text": "References"
  }
]